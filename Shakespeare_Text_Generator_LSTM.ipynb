{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r2myc2McpUi"
      },
      "source": [
        "# Text Generation in Shakespeare's Style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBld5HC4ZsTa"
      },
      "source": [
        "**Import Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhodkVkO--5I"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyf7Kp60_ILJ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nfLpnorgFEK"
      },
      "source": [
        "**Download Shakespeare Dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it5eFMpWgVzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8238b85e-0d54-4b77-bdc1-0ffa053e609c"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O sonnets.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-25 04:49:00--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 108.177.126.128, 108.177.127.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘sonnets.txt’\n",
            "\n",
            "sonnets.txt         100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-01-25 04:49:01 (77.6 MB/s) - ‘sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkj1yS0dZzIk"
      },
      "source": [
        "**Define Tokenizer and prepare training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXslMiTJ_mML"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data= open('sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split('\\n')\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFRD67qOAKoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b30d48-965b-46e1-9268-1bbd547b46a4"
      },
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  # print(\"LIST = \"+str(token_list))\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    # print(n_gram_sequence)\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# print(len(input_sequences))\n",
        "\n",
        "# #pad sequences\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "\n",
        "print(max_sequence_len, total_words)\n",
        "\n",
        "input_sequences = np.array(pad_sequences(input_sequences, padding='pre', maxlen=max_sequence_len))\n",
        "\n",
        "#create predictors and labels\n",
        "xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 3211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ze5-6BiabJi"
      },
      "source": [
        "**Define the Model Architecture and start training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5yBAHb8PhS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e77ae7-7cd1-4da1-c1d1-a9c4887e75d1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Bidirectional(LSTM(96)))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 113, 100)          284400    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 113, 300)          301200    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 113, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 192)               304896    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1422)              274446    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2844)              4047012   \n",
            "=================================================================\n",
            "Total params: 5,211,954\n",
            "Trainable params: 5,211,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfo4cgX-QrR5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6bcbc00-ad12-4547-d77b-fb2803df3e12"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "history = model.fit(xs, ys, epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 58s 128ms/step - loss: 5.4444 - acc: 0.0805\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 46s 118ms/step - loss: 5.2167 - acc: 0.0906\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 45s 116ms/step - loss: 5.0802 - acc: 0.0984\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 45s 116ms/step - loss: 4.9581 - acc: 0.1105\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 4.8565 - acc: 0.1217\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 44s 113ms/step - loss: 4.7616 - acc: 0.1273\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 4.6784 - acc: 0.1340\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 4.5942 - acc: 0.1418\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 4.5218 - acc: 0.1497\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 4.4440 - acc: 0.1577\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 4.3722 - acc: 0.1665\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 43s 110ms/step - loss: 4.3039 - acc: 0.1728\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 43s 111ms/step - loss: 4.2236 - acc: 0.1827\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 42s 109ms/step - loss: 4.1578 - acc: 0.1919\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 42s 109ms/step - loss: 4.0846 - acc: 0.1976\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 42s 108ms/step - loss: 4.0104 - acc: 0.2059\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 42s 107ms/step - loss: 3.9413 - acc: 0.2157\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 41s 106ms/step - loss: 3.8644 - acc: 0.2274\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 3.8023 - acc: 0.2350\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 41s 104ms/step - loss: 3.7212 - acc: 0.2458\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 3.6501 - acc: 0.2584\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 41s 105ms/step - loss: 3.5852 - acc: 0.2668\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 3.5209 - acc: 0.2765\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 3.4448 - acc: 0.2878\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 3.3752 - acc: 0.2991\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 3.3125 - acc: 0.3068\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 3.2396 - acc: 0.3166\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 3.1950 - acc: 0.3280\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 3.1225 - acc: 0.3418\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 3.0561 - acc: 0.3517\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.9921 - acc: 0.3634\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.9337 - acc: 0.3809\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.8743 - acc: 0.3903\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 2.8150 - acc: 0.4059\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 2.7624 - acc: 0.4122\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 2.7078 - acc: 0.4244\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.6565 - acc: 0.4347\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.6018 - acc: 0.4486\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.5424 - acc: 0.4645\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.4913 - acc: 0.4750\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.4375 - acc: 0.4870\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.3927 - acc: 0.4987\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.3450 - acc: 0.5069\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 2.3014 - acc: 0.5210\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.2790 - acc: 0.5270\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.2104 - acc: 0.5433\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.1734 - acc: 0.5463\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.1131 - acc: 0.5649\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 2.0723 - acc: 0.5789\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.0201 - acc: 0.5873\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 2.0079 - acc: 0.5936\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 1.9576 - acc: 0.6004\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 40s 101ms/step - loss: 1.9223 - acc: 0.6094\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 1.8793 - acc: 0.6186\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 1.8561 - acc: 0.6323\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 40s 102ms/step - loss: 1.8171 - acc: 0.6372\n",
            "Epoch 57/100\n",
            "268/390 [===================>..........] - ETA: 12s - loss: 1.7434 - acc: 0.6571"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9bdea560ebbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7J15uDUa5_t"
      },
      "source": [
        "**Generate 100 next words with an initial sample sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EOATwDaWntP"
      },
      "source": [
        "\n",
        "def predict_next_words(seed_text, next_words):\n",
        "  for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predict_x=model.predict(token_list) \n",
        "    predicted=np.argmax(predict_x,axis=1)\n",
        "    # predicted = model.predict_classes(token_list, verbose=0)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == predicted:\n",
        "        output_word = word\n",
        "        break\n",
        "    seed_text += \" \" + output_word\n",
        "\n",
        "  print(seed_text)\n",
        "  return seed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JytBQhTjXuJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384f746f-2fb0-46d3-e2a6-443e559a9e48"
      },
      "source": [
        "seed_text = \"1THREEPIO\"\n",
        "next_words = 100\n",
        "\n",
        "\n",
        "generated_text = predict_next_words(seed_text, next_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1THREEPIO han red leader rendezvous at mark six one rebel base one coming in listen and you are to happen any well upset the force will be with you always sounds like they than word in here this is the jump to light speed and scheduled to fry the jedi knights were the force is done if he was even enough of the jump to light speed is under control you've ought to be able to get us here the detention planet of anchorhead this is kenobi now you're nothing if five of my father like you to dump it but\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHC4b-EpZdeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3e38cae7-ee9d-40c8-eaa2-e609f8e1d17f"
      },
      "source": [
        "seed_text = \"why lovest thou that which thou receivest not gladly,\"\n",
        "generated_text = predict_next_words(seed_text, next_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "why lovest thou that which thou receivest not gladly, gladly change things life dead brow new lack lie to my life still doth some cross ' bred another youth their night ' still doth date rage of life but therein quite gone straight lack dead face dead young thee hour mine eye some ill alone doth stay thy hate must care you moan still o'er hell or woe remain new fire ' must do bring all rest fitted tongue forgot thus three near contents stay your place must seen have near forth o'er truth still truly dwell to groan things tend ill doth hide to thee in me bring\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}